Hey, Vsauce, Michael here. Where is your mind? Is it in your head? I mean, that's where your brain is and your brain helps you remember and plan and make judgments and solve problems. But you also remember and plan with phones and notes and calendars and you make judgments and solve problems with all sorts of things. You know, when you think about it, the brain is really just a wet lump of fat and protein, no firmer than a blob of tofu. But the mind is huge. It's an ever-expanding organ of tissue and wood and stone and steel and people because of communication. Communication allows us to even make other people extensions of our minds. We can access their memories and perceptions and knowledge by simply asking. Or not. I don't need to learn how to fix a car and practice medicine and vulcanize rubber or remember everything. Other people are doing that for me just as I do things for them. We are a species of individuals that is also one big interdependent lumbering growth, a frantic blur of flesh and concrete, a techno-sapien powered by imaginations and passions made real by a hallowed faculty we call reason. Reason, it is said, guides us to truer knowledge and better decisions. It's allowed us to increase life expectancy, suffer less, work together better, and it's bound to take us further and higher until the end of time. Or is it? The organ we use to reason takes millions of years to evolve, but the fruits of reason grow rapidly and are ever-accelerating. Over the next four decades, we are expected to build the equivalent of another New York City every month. And more concrete was installed in the last two decades outside the United States than the U.S. installed during the entire 20th century. This growth means that quality of life around the world is rising. It means that electricity, manufactured goods, food, comfort, and transportation are all becoming more common and accessible. But there are hints that reason and logic are struggling against the complexity of it all, against our growing dependence on the things we've built and their unintended consequences. Nearly every part of life as we know it today involves or relies on a process that releases molecules with lopsided electrical charges. This property causes them to absorb and re-emit thermal radiation, pinging it around so that it escapes into space more slowly. Having more warmer parcels of air means stronger weather events. They can't be pinned to any particular extreme storm, but they make extreme storms in general more extreme and frequent. What's at stake isn't just bad weather, it's disaster. It's more lives lost, more property lost. It's more droughts, more hunger, more famine, more people needing refuge, and an even greater reliance on the very things that caused the problem in the first place. In total, we release about 51 billion tons of such gases every year, and we need to release zero. But how do you rethink everything? Who gets to direct the costs and trade-offs? How do you achieve collaboration between nearly every local and national government when what works in one place won't work everywhere? When decisions affect jobs in one place and food in another? When not just things need to be rethought, but also habits and traditions and values? How do you achieve consensus when a problem isn't obvious to the senses, is far away in space and time, requires solutions that affect people in different ways, and, as a product of science, always carries some uncertainty? The philosopher Timothy Morton calls something so massively distributed in time and space, and so viscous, so sticky that it adheres to all that touch it, a hyperobject. Every civilization that grows at the speed of reason must at some point face hyperobjects. In fact, the fact that we still haven't found evidence of intelligent life beyond Earth has been brought up as evidence that some sort of great filter might exist that few civilizations manage to get past. That a hyperobject, like our impact on the planet, might be such a great filter is not a new idea. What it might take to solve it is the topic of Bill Gates' How to Avoid a Climate Disaster. And I decided to do this video in partnership with him and his team because the way we deal with hyperobjects reveals a lot about the mind. It's easy and common to think that we would all be better off if everyone was just more rational, right? But what if reasoning wasn't built for what we've become? Let's begin by looking at behavioral inertia. Behavioral inertia is the tendency to keep doing what you're already doing, status quo bias. It can be a frustrating bias if you desire change, but its origin isn't a flaw. If an organism has managed to survive long enough to reproduce and provide and care for its offspring, then the state of its world was sufficient for its genes to spread. That's all it takes to persist. The types of organisms we see around us will naturally be those that managed to persist and didn't, after reaching that point, rock the boat too much. So behavioral inertia can help slow down the accumulation of unintended consequences and the loss of ideas that work, but it can also slow down innovation and adaptation. If the environmental impacts of our society were more immediate and unignorable, it wouldn't be so tempting to apply this inertial break. But emissions are invisible and their consequences aren't immediate or local. They impact future people and people far away, those who are different from us, poorer than us, people we will never meet. This may be one of the first challenges advancing civilizations face, wielding not just the power of technology and distributed cognition, but also the responsibilities. Extending the mind is really cool, but whether or not a species can extend their empathy might be a great filter. Surely, reasoning will allow us to do that, right? Well, what is reasoning? Well, reasoning is a way of making inferences. An inference is a piece of new information extracted from the information you already have. We make inferences all the time. Every living thing does. For example, we don't have measuring tape tentacles that shoot from our eyes. And what actually enters our brain is just a 2D image, but nonetheless, our brains can infer depth by attending to cues like stereopsis, occultation, perspective, parallax, size. When this happens, we accept it as reality. We aren't aware of the visual processing that made it possible, and we don't have to be. If, however, we do consciously consider why a certain conclusion was reached, well, then boom, that's reasoning. Reasoning is the process of making inferences, not automatically and instinctively, but by looking at facts and seeing what conclusions they support. When Eratosthenes calculated the circumference of the Earth to within a percentage or two of the value accepted today, he didn't do it by measuring the Earth and he didn't just perceive it as self-evident. No, he inferred it from what he knew about shadows and how long it took camels to move. Stories like that make it easy to believe that reasoning evolved because it supercharged our cognitive abilities. I mean, it clearly moves us towards truer conclusions, better decisions, and knowledge no other species could infer. Attempts to describe the rules of good, orderly reason became logic and mathematics, concepts so general and abstract that while we were still animals, armed with them, we were no longer beasts. But that's the rub, isn't it? If reasoning is so great, why are we the only species with such a sophisticated grasp of it? And if its purpose is truth and good judgment, why don't we all agree on everything? It's tempting to think that disagreements happen because, well, I am being rational, but those who disagree with me are being irrational. If only people would just use logic and reason. What's happened to the world? Well, that's a fair complaint if you're arguing over logic puzzles, but the world is not a logic puzzle. This, however, is one. Paul is looking at Mary. Mary is looking at Peter. Paul is married. Peter is unmarried. Is a married person looking at an unmarried person? Yes? No? Or not enough information to decide? Think about it. The answer is yes. You may have thought there's no way to know because we don't know if Mary is married. But look, she either is or she isn't. And if she is, well then she, a married person, is looking at Peter, an unmarried person. If she isn't, then Paul, a married person, is looking at her, an unmarried person. So no matter what Mary's deal is, the answer will be yes. When people get this puzzle wrong and the correct answer is explained to them, they almost always immediately see why it's right and change their mind. Life is not always like that. Let's take a look at a logical syllogism. All elephants are awesome. Michael is an elephant. Therefore Michael is awesome. The conclusion is logically valid. It follows from the assumptions. But are the assumptions true? No. I am not an elephant. Also, this premise is subjective. I mean, what does it mean to be awesome? Can we measure it with an ossimometer? So you can see why when analyzing something like our impact on the planet, logic can only be a partial tool. If some people have more to lose than others, who gets to decide which assumptions are fair? Still, though, it would seem that reasoning should be able to help here. If each of us would just attend only to the facts, surely we'd all recognize the same reasonable approach. Problem is, that's not how reasoning works. Since the scientific study of human reasoning began about a hundred years ago, it has been found again and again that not only are we bad at reasoning, lazy and biased, but we actually seem almost programmed to be bad. Like the flaws are intentional. In an episode of Mind Field, I once used a magician to pull off a little experiment. He asked people to look at two faces and choose which of the two they would prefer to work with, placing their preferences in one pile and those they rejected into another. Then, the pile of people they picked were shown again, and each person was asked to provide a reason for why they chose that person. But with a little sleight of hand, the magician managed to sneak in some of the faces they had just rejected. Amazingly, the majority of people didn't even notice the trick. Not only that, they were able to effortlessly explain the reasons behind their choice. A choice they never actually made. Remembering faces you've only seen briefly isn't the easiest thing to do, but other studies have shown that even if the task involves answering questions about one's political beliefs, things we would seemingly have a firmer grasp on, nearly half of participants will fail to notice that the answers they gave have been reversed when they're later asked to explain them. Point is, we seem practically built to give reasons for whatever we think we must, and not the reasons we actually used to reach a conclusion. What if we don't even use reasons to reach conclusions? Well, let's talk about intuitions. Our brains have evolved over millions of years to react to the world around us in brilliant ways with little to no input from us. For example, when you notice that someone is upset, you don't consciously think, hmm, okay, so, uh, well their eyebrows are kind of in that position and their speech seems curt, their posture is... These are all reasons to conclude that they are upset. No. Instead, the belief that they may be upset was just apparent. You intuited it. You know it without exactly knowing how you came to know it. The mood-recognizing parts of your brain operate in a way that is opaque to your awareness. But if someone asks you, why do you think they're upset, you can nonetheless produce all sorts of reasons. Some may have actually been the ones your brain attended to, but they're all just guesses. Instead of using reasoning to come to conclusions, we use conclusions to come to reasons. Now, to be fair, we can go the other way. We love puzzles, and when we don't have a strong intuition either way, we can sit down and mull over various reasons to think one thing or another. Our love of puzzles suggests that reasoning has a survival value. Organisms that found it pleasurable would be more likely to use it. But when we reason alone, even when we have no motivation to reach any particular conclusion, we still exhibit deep biases that seem less like mistakes and more like features. For example, it's been shown that between two otherwise similar products, people will prefer to buy the one with more functions, even if they don't want those functions, never plan to use them, and think they're all pointless and overly complicated. Why? Well, it might be that we find such decisions easier to justify to others. We won't wind up being potentially embarrassed when someone asks why we didn't get the product with more functions. Well, after decades of findings like this, Hugo Mercier and Dan Sperber began to hypothesize that reasoning didn't evolve to help us make better decisions, but instead to help us be social. Intuitions inhabit a cognitive niche on this planet. We aren't strong or sharp or hidden or venomous. Instead, our advantage comes from cognition, reasoning, and cooperation. We can plan hunts, build traps, and engage in coordinated strategies that can be tested and modified on the fly, not by millennia of evolution. Reason allows us to do those things. It's hard to convince people that your intuitions are true, but if you can give reasons for them, it's a whole heck of a lot easier to convince people that you're right. Being able to argue over what the best thing to do is is vital when it comes to coordinating action. Reasons also allow us to justify ourselves in the eyes of others, to explain who we are and express the kinds of reasons we like, what others can expect from us, and what we will likely expect from them. This social theory of reasoning helps explain why two people can earnestly and rationally arrive at two different views. They each have their own unique brain and values and dispositions and experiences, and those are what drove their thinking. The reasons they give may or may not be the real reasons they came to their conclusions, but it's the best anyone can do. The social theory also explains why people tend to give such weak reasons for their beliefs at first, or when their intended audience doesn't need much convincing. It would be a waste of time and cognitive resources to construct grand slam reasons for everything I said and did and thought when it wasn't necessary. Instead, I can offload some of that work to other people. For example, if I say, I want to have lunch at ABC Burgers, well my friend might respond, Nah, no thanks, I had burgers yesterday. And I might reply back, oh, well that's no problem, they also have hot dogs and great salads. But if my friend said, nah, no thanks, I'm trying to spend less money eating out this month, I could reply, oh, well ABC Burgers is really cheap and I've got a coupon. Now what's going on here is that I'm providing reasons only as my friend presses for them. If they press harder and harder, my reasons will become better and better until either I win them over or we come to some different, more harmonious decision. So when people appear to be lazy reasoners, or to have bad reasons, or none at all, it's usually just the case that they're using reason as it evolved to function, socially. It starts off weak, improving if others push it, and always tailoring its work to the intended audience. The social theory of reasoning can even explain the existence of biases that otherwise make little sense. For example, it would seem that in coming to conclusions about the world, it would behoove an organism to pay particular attention to information that went against what it believed. I mean, that way, they would be able to adjust their beliefs, making them truer, more general, and more complete. To a certain extent, that is what happens, but not always. When someone does their own research, they often come to the very conclusion they wanted in the first place. This is called confirmation bias, our tendency to look for, prefer, and interpret information so that it confirms what we already think. It frustrates our ability to accept new, inconvenient data, and is a problem for the intellectualist view of reason. If reason is for finding truth and making better decisions, why would it have this major weakness? Well, because, the social theory says, reasoning is a group activity. Let's say that I think option A is true and the best, and you think option B is true and the best. Well, if we both researched both options and sifted through reasons in support of both options, we would both have twice the work to do than we would if, instead, I simply came up with reasons for why I was right and you attended to reasons for why you were right. The confirmation bias at least halves the cognitive work that must be done. Now, sometimes, a lone reasoner will have a bad idea or a decent idea with some bad parts. The reasons they have to justify for and argue for it will be sufficient for them and those who intuitively agree, but they may be weak. However, subjected to deliberation, put forth into the machine of collective thought, it can be evaluated and judged not by one mind or a group of minds thinking alike, but by something very special, the crowd. Humans have long known of the wisdom of the crowds, the phenomenon by which a collection of many people can process information into a conclusion better than any one person could do alone. It's why we don't trust big decisions to a single person, no matter how educated or powerful they are. Instead, we ask a group of people to deliberate, to reason together. In this way, the biases and errors of each is smoothed out and the decision wiser. In a famous example, it's been repeatedly shown that if you ask a bunch of people to guess how many jelly beans are in a jar, you'll find that the average of all their answers is closer to the real number than any one individual was alone. What happens is that although some people may guess a number that is like way too big, that mistake is balanced out by the fact that others will inevitably guess a number that is way too small. Altogether, their disagreement evens out into spectacular accuracy. We have now arrived at the problem. Reasoning evolved to be used socially, where many different perspectives had to all deliberate towards a common conclusion. Such contexts are becoming less and less common and it is becoming easier and easier to simply be a lone reasoner, justifying only a particular viewpoint without doing the harder work of deliberating and acting. The internet gives voices to more perspectives than ever before in our history, but it also makes it easy to disengage from accountability and to find places where everyone believes what you do. Furthermore, because of technology, we confront more issues more rapidly than ever before that we are expected to have opinions about, and the growing complexity and specialization of the modern world makes it difficult for each of us to have well-informed, prepared reasons for the accelerating accretion of intuitions we must form. In response, we look for people who can defend our intuitions for us. The reasons they give don't have to be good, just good enough that we can feel like justification exists. In the past, unconvincing reasons had to be painted on sandwich boards, but now the democratization of communication means that even unpopular, unconvincing, nonsensical ideas can be presented with the same trust-inducing typefaces and professional look as common ones. People can challenge the weak reasons of others, show them to be contradictory and produce better reasons for their side, but to what end? It's all preparation for a debate that never comes. We each play a very small role in deciding how society is run. Even if a good-faith discussion between a representative slice of America came to a resolution, if nothing can come of it, why not just throw shade and sick burns or revel in the pleasure of reasoning by treating everything like a big giant puzzle? It's easy to think that it doesn't matter, because after all, those in charge, the brilliant scientists and powerful billionaires, will surely come to the rescue. Some giant techno-salvation is surely on the horizon. Perhaps it is, but everything we know about reason suggests that those implementing it should be held accountable by as many different perspectives as possible. Leaders could lead deliberations and be elected for their ability to moderate social reasoning. But that's boring. Why lead when you could follow? Look at what some people believe and generate reasons for why they're right, and they'll love it. Of course, the hard work, the real work, the work that truly elevates us on this planet is not in telling people that they're right, but in trying to convince others. And in doing so, use reason as it evolved to be used. The future of reason may, in fact, be the past of reason. In practice, what does all this look like? Well, some researchers have gone so far as to recommend National Deliberation Days, where citizens celebrate by literally joining small groups and talking through their opinions and comparing reasons. Tests of such strategies have shown that a return to the small, targeted discussions our reasoning abilities evolved to excel in leaves all participants with a greater understanding of not just what they believe and why, but about decisions that could actually be made and actions that could be taken. Others have gone even further, recommending that the future of reason at its best is the construction of a lotocracy, a form of government where decisions are made not by elected leaders, but by people literally chosen at random. We decide the fate of a person this way. Why not the fate of the people? What if decisions were made not by politicians alone, but at least occasionally by groups of actual citizens representing differences in thought, not just geography, who were brought together and paid for their time to learn from experts and then deliberate on an assigned issue until a conclusion was reached or, at the least, a recommendation? Instead of being motivated by re-election, money, attention, and power, individuals chosen at random would have only their conscience to guide them. Special interests and corporations wouldn't be able to cozy up to those likely to be elected because if any one of us could someday serve, they'd have to cozy up to and protect all of us. Instead of the learning and deliberation being done by people you will never meet, with offices and buildings you can't access, gradually, over time, more and more of your very own neighbors would have had the honor. People chosen at random would obviously lack the same celebrity status and mandate that elected leaders cultivate and achieve. And iconic figures we relate to aren't bad, but our understanding of reasoning is making it more and more clear that we evolved not to leave the thinking up to a few great minds, but to the authority of the great mind, the lumbering organ of thought that is everyone and everything. This is, in fact, how democracy first worked. When lotteries were used to fill many political positions in ancient Athens, Aristotle explained that the appointment of magistrates by lot is thought to be democratic, and the election of them is oligarchic. An oligarchy is government by only a small number of people. Look, regardless of how reason is brought back to its social roots, if we can build more and better arenas for deliberation and use them to apply reason properly to hyperobjects like the impact of our emissions on the planet, we'll have taught one heck of a lesson to people a hundred, a thousand years in the future. I like to think that although widening participation will be difficult, it might provide us with a kind of existential security. The impact of emissions on our planet is not going to be the last hyperobject we face. If we can do a good job with it, maybe far in the future, when our civilization has advanced to the point at which, I don't know, people can be quantumly recreated or something, they'll look back at our time and say, hey, let's bring them all back to life. We could use the cooperative abilities they had then. Ultimately, the old saying that history is the great teacher isn't a bad guide. We will all someday be teachers ourselves because someday we will all be history. We will someday be the ancients. And we can choose what that will mean. And as always, thanks for watching.
